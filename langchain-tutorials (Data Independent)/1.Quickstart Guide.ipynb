{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPIDecfKi25aOSeOOMFBuBJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Ref (main): https://github.com/gkamradt/langchain-tutorials/blob/main/getting_started/Quickstart%20Guide.ipynb\n","\n","https://www.youtube.com/watch?v=kYRB-vJFy38&list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5&index=3\n","\n","Ref:\n","\n","https://python.langchain.com/en/latest/getting_started/getting_started.html\n","\n","https://blog.csdn.net/wenxingchen/article/details/130474611"],"metadata":{"id":"ubUP7y5f_K0c"}},{"cell_type":"code","source":["!pip install langchain\n","!pip install openai\n","!pip install google-search-results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbgeUOq1_M2x","executionInfo":{"status":"ok","timestamp":1685511765106,"user_tz":-480,"elapsed":24243,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"2697c7e3-44c8-420e-f4e0-a86a6076a7c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting langchain\n","  Downloading langchain-0.0.186-py3-none-any.whl (949 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.7/949.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n","Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n","Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n","  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n","Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.186 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n","Installing collected packages: openai\n","Successfully installed openai-0.27.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting google-search-results\n","  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n","Building wheels for collected packages: google-search-results\n","  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32002 sha256=82488e09140f1d3472551c1a42901e7ac00d23601a2da3db168a4181d286ad15\n","  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n","Successfully built google-search-results\n","Installing collected packages: google-search-results\n","Successfully installed google-search-results-2.4.2\n"]}]},{"cell_type":"code","source":["import os\n","from langchain.llms import OpenAI\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"\"\n","os.environ[\"SERPAPI_API_KEY\"] = \"\"\n","\n","llm = OpenAI(openai_api_key=\"OPENAI_API_KEY\")"],"metadata":{"id":"jhfnqqsR-_Nq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**LLMs: Get predictions from a language model**"],"metadata":{"id":"DBkJWDcNUANE"}},{"cell_type":"code","source":["from langchain.llms import OpenAI\n","\n","llm = OpenAI(temperature=0.9)\n","text = \"What would be a good company name for a company that makes colorful socks?\"\n","llm(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Iy1zZaFk_IcK","executionInfo":{"status":"ok","timestamp":1685511767961,"user_tz":-480,"elapsed":907,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"2f49efae-4600-42c4-9e1f-db3a082e900a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nRainbow Sockery'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["**Prompt Templates: Manage prompts for LLMs**"],"metadata":{"id":"JNzFEfASUKjq"}},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"product\"],\n","    template=\"What is a good name for a company that makes {product}?\"\n",")\n","prompt.format(product=\"colorful socks\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"HH3vbo4IAk2R","executionInfo":{"status":"ok","timestamp":1685511767961,"user_tz":-480,"elapsed":6,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"6bfe86e3-57e7-48ac-92c7-71be2a9a3fa1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'What is a good name for a company that makes colorful socks?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["**Chains: Combine LLMs and prompts in multi-step workflows**"],"metadata":{"id":"MU1VQm25UPcb"}},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","from langchain.llms import OpenAI\n","\n","llm = OpenAI(temperature=0.9)\n","prompt = PromptTemplate(\n","    input_variables=[\"product\"],\n","    template=\"What is a good name for a company that makes {product}?\",\n",")\n","\n","from langchain.chains import LLMChain\n","chain = LLMChain(llm=llm, prompt=prompt)\n","chain.run(\"colorful sucks\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3_mWc3NoBCaU","executionInfo":{"status":"ok","timestamp":1685511769462,"user_tz":-480,"elapsed":1506,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"dc79ab8f-c4be-4717-9bb3-0e5720132ece"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nRainbow Suckers.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["**Agents: Dynamically Call Chains Based on User Input**"],"metadata":{"id":"CyyLhh2eUTZK"}},{"cell_type":"code","source":["from langchain.agents import load_tools\n","from langchain.agents import initialize_agent\n","from langchain.agents import AgentType\n","from langchain.llms import OpenAI\n","\n","# First, let's load the language model we're going to use to control the agent.\n","llm = OpenAI(temperature=0)\n","\n","# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n","tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n","\n","\n","# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n","agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n","  \n","# Now let's test it out!\n","agent.run(\"今天星期幾, 歷史上發生什麼大事?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"iNqEyfOvBh_l","executionInfo":{"status":"ok","timestamp":1685511784251,"user_tz":-480,"elapsed":14801,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"84b9158f-5bf4-4fe2-ecc7-c7059c19b54c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m I need to find out what day it is today and what historical event happened on that day.\n","Action: Search\n","Action Input: \"What day is it today\"\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3mToday's holidays · Loomis Day · National Creativity Day · National E-Bike Day · National Hole In My Bucket Day · World Multiple Sclerosis Day · Carly Lawrence's ...\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I need to find out what historical event happened on this day\n","Action: Search\n","Action Input: \"Historical events on [today's date]\"\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3mToday's Historical Events · Royal Coronation · Joan of Arc Burned at the Stake · Margaret of Anjou Crowned · Columbus Departs on Third Voyage · Portuguese Abandon ...\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n","Final Answer: Today is World Multiple Sclerosis Day and historical events that happened on this day include the Royal Coronation, Joan of Arc Burned at the Stake, Margaret of Anjou Crowned, Columbus Departs on Third Voyage, and Portuguese Abandon.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'Today is World Multiple Sclerosis Day and historical events that happened on this day include the Royal Coronation, Joan of Arc Burned at the Stake, Margaret of Anjou Crowned, Columbus Departs on Third Voyage, and Portuguese Abandon.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["**Memory: Add state to chains and agents**"],"metadata":{"id":"tKQ8VrOrUzkn"}},{"cell_type":"code","source":["from langchain import OpenAI, ConversationChain\n","\n","llm = OpenAI(temperature=0)\n","conversation = ConversationChain(llm=llm, verbose=True)\n","\n","conversation.predict(input=\"Hi there!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"9ttcm8OlU0wQ","executionInfo":{"status":"ok","timestamp":1685511785456,"user_tz":-480,"elapsed":1223,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"35adca35-3691-48eb-9356-1fb99536f5e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi there!\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Hi there! It's nice to meet you. How can I help you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"EZN4KVR9U5pn","executionInfo":{"status":"ok","timestamp":1685511789375,"user_tz":-480,"elapsed":3922,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"49da212b-08cf-4894-9896-4a4de53a75ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi there!\n","AI:  Hi there! It's nice to meet you. How can I help you today?\n","Human: I'm doing well! Just having a conversation with an AI.\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["conversation.predict(input=\"What was the first thing I said to you?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"MsvN3jb7U8d5","executionInfo":{"status":"ok","timestamp":1685511791387,"user_tz":-480,"elapsed":2026,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"81a8d6a3-6dd5-4ed2-f192-fb9bd4266be7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi there!\n","AI:  Hi there! It's nice to meet you. How can I help you today?\n","Human: I'm doing well! Just having a conversation with an AI.\n","AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n","Human: What was the first thing I said to you?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["' You said \"Hi there!\"'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["conversation.predict(input=\"what is an alternative phrase for the first thing I said to you?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"N4NbZJcNU9_s","executionInfo":{"status":"ok","timestamp":1685511792922,"user_tz":-480,"elapsed":1541,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"7148d07b-efd0-4d4a-fcc2-9581ef343de3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi there!\n","AI:  Hi there! It's nice to meet you. How can I help you today?\n","Human: I'm doing well! Just having a conversation with an AI.\n","AI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n","Human: What was the first thing I said to you?\n","AI:  You said \"Hi there!\"\n","Human: what is an alternative phrase for the first thing I said to you?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["' An alternative phrase for the first thing you said to me could be \"Greetings!\"'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]}]}